{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP/y6Xm3b/KLlW1tySeeOPB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "34c48982a0644056a50ec3e2a0970eeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0c9c014c5007477a8fc55055297047de",
              "IPY_MODEL_0492325b58184385b533638944c8aeb4",
              "IPY_MODEL_9a7f062781ef4c9eb082be2b55b0bd92"
            ],
            "layout": "IPY_MODEL_a4247d6834924c80817193949cd07aa8"
          }
        },
        "0c9c014c5007477a8fc55055297047de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56101ead3e44409cb07043251089c298",
            "placeholder": "​",
            "style": "IPY_MODEL_b36c8703e96b4e3494b565f1583eb2ac",
            "value": "Batches: 100%"
          }
        },
        "0492325b58184385b533638944c8aeb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f9972cc1eb2409abca4355a61e6ae18",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_58a6718f25d0444a84fb2504390421b8",
            "value": 5
          }
        },
        "9a7f062781ef4c9eb082be2b55b0bd92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b136711b5e64062993c4f7313b6f038",
            "placeholder": "​",
            "style": "IPY_MODEL_048606f7cdd94f29a67894d2c0a50a4d",
            "value": " 5/5 [00:01&lt;00:00,  3.30it/s]"
          }
        },
        "a4247d6834924c80817193949cd07aa8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56101ead3e44409cb07043251089c298": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b36c8703e96b4e3494b565f1583eb2ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0f9972cc1eb2409abca4355a61e6ae18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58a6718f25d0444a84fb2504390421b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7b136711b5e64062993c4f7313b6f038": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "048606f7cdd94f29a67894d2c0a50a4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hackone7/NAVIILM/blob/main/Untitled11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LgQNDaSsOkcI"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "buCea5orQfzH"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages (run once)\n",
        "!pip install --quiet gradio rapidfuzz gTTS pydub sentence-transformers scikit-learn networkx\n",
        "# Note: sentence-transformers will download model weights on first run (internet)\n"
      ],
      "metadata": {
        "id": "HDUMT7wWNgWm"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "0HrCR9SRQyAf",
        "outputId": "5573c47d-a8fe-4f1e-9355-4d6425c1fef6"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-fd015fa9-0108-45cf-afce-f3a09e56b77d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-fd015fa9-0108-45cf-afce-f3a09e56b77d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving bigdata.json to bigdata (3).json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset from the environment path you uploaded\n",
        "import json, os\n",
        "DATA_PATH = '/content/bigdata.json'   # <-- your uploaded file path\n",
        "print(\"Using dataset path:\", DATA_PATH)\n",
        "if not os.path.exists(DATA_PATH):\n",
        "    # If not found, Colab will prompt upload\n",
        "    try:\n",
        "        from google.colab import files\n",
        "        print('bigdata.json not found at', DATA_PATH, ' — please upload it now.')\n",
        "        uploaded = files.upload()\n",
        "        for fn in uploaded:\n",
        "            open('/content/bigdata.json' + fn, 'wb').write(uploaded[fn])\n",
        "            print('Uploaded', fn)\n",
        "    except Exception as e:\n",
        "        raise RuntimeError(\"Dataset not found and upload failed.\") from e\n",
        "\n",
        "with open(DATA_PATH, 'r', encoding='utf-8') as f:\n",
        "    raw = json.load(f)\n",
        "\n",
        "# Many uploaded datasets use top-level key \"CampusData\" — handle both cases\n",
        "if isinstance(raw, dict) and 'CampusData' in raw:\n",
        "    campus = raw['CampusData']\n",
        "else:\n",
        "    campus = raw\n",
        "\n",
        "print(\"Loaded campus. Blocks found:\", list(campus.keys())[:20])\n",
        "# quick peek:\n",
        "import pprint\n",
        "first_block = next(iter(campus))\n",
        "pprint.pprint({first_block: campus[first_block]})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PzttCoAKNlF6",
        "outputId": "0992bfd4-1d93-406f-af46-66a8857ac453"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using dataset path: /content/bigdata.json\n",
            "Loaded campus. Blocks found: ['EngineeringBlock', 'SVH_Block', 'FacultyBlock', 'GeneralFacilities', 'IGSM_Block']\n",
            "{'EngineeringBlock': {'description': 'The Engineering Block consists of fully '\n",
            "                                     'furnished classrooms, computer labs, '\n",
            "                                     'faculty rooms, water coolers, and '\n",
            "                                     'vending machines. It is designed for '\n",
            "                                     'B.Tech students with easy access to '\n",
            "                                     'academic facilities.',\n",
            "                      'rooms': [{'Location': 'Ground Floor',\n",
            "                                 'RoomID': 'EB101',\n",
            "                                 'Type': 'Classroom'},\n",
            "                                {'Location': 'Ground Floor',\n",
            "                                 'RoomID': 'EB102',\n",
            "                                 'Type': 'Computer Lab'},\n",
            "                                {'Location': 'Ground Floor',\n",
            "                                 'RoomID': 'EB103',\n",
            "                                 'Type': 'Computer Lab'},\n",
            "                                {'Location': 'Ground Floor',\n",
            "                                 'RoomID': 'EB104',\n",
            "                                 'Type': 'Computer Lab'},\n",
            "                                {'Location': 'Ground Floor',\n",
            "                                 'RoomID': 'EB105',\n",
            "                                 'Type': 'Computer Lab'},\n",
            "                                {'Location': 'Ground Floor',\n",
            "                                 'RoomID': 'EB106',\n",
            "                                 'Type': 'Classroom'},\n",
            "                                {'Location': '1st Floor',\n",
            "                                 'RoomID': 'EB201',\n",
            "                                 'Type': 'Classroom'},\n",
            "                                {'Location': '1st Floor',\n",
            "                                 'RoomID': 'EB202',\n",
            "                                 'Type': 'Classroom'},\n",
            "                                {'Location': '1st Floor',\n",
            "                                 'RoomID': 'EB203',\n",
            "                                 'Type': 'Classroom'},\n",
            "                                {'Location': '1st Floor',\n",
            "                                 'RoomID': 'EB204',\n",
            "                                 'Type': 'Classroom'},\n",
            "                                {'Location': '1st Floor',\n",
            "                                 'RoomID': 'EB205',\n",
            "                                 'Type': 'Classroom'},\n",
            "                                {'Location': '1st Floor',\n",
            "                                 'RoomID': 'EB206',\n",
            "                                 'Type': 'Classroom'},\n",
            "                                {'Location': '1st Floor',\n",
            "                                 'RoomID': 'EB207',\n",
            "                                 'Type': 'Classroom'},\n",
            "                                {'Location': '1st Floor',\n",
            "                                 'RoomID': 'EB208',\n",
            "                                 'Type': 'Computer Lab'},\n",
            "                                {'Location': '2nd Floor',\n",
            "                                 'RoomID': 'EB301',\n",
            "                                 'Type': 'Classroom'},\n",
            "                                {'Location': '2nd Floor',\n",
            "                                 'RoomID': 'EB302',\n",
            "                                 'Type': 'Faculty Room'},\n",
            "                                {'Location': '2nd Floor',\n",
            "                                 'RoomID': 'EB303',\n",
            "                                 'Type': 'Faculty Room'},\n",
            "                                {'Location': '2nd Floor',\n",
            "                                 'RoomID': 'EB304',\n",
            "                                 'Type': 'Classroom'},\n",
            "                                {'Location': '2nd Floor',\n",
            "                                 'RoomID': 'EB305',\n",
            "                                 'Type': 'Classroom'},\n",
            "                                {'Location': '2nd Floor',\n",
            "                                 'RoomID': 'EB306',\n",
            "                                 'Type': 'Classroom'},\n",
            "                                {'Location': '3rd Floor',\n",
            "                                 'RoomID': 'EB401',\n",
            "                                 'Type': 'Classroom'},\n",
            "                                {'Location': '3rd Floor',\n",
            "                                 'RoomID': 'EB402',\n",
            "                                 'Type': 'Classroom'},\n",
            "                                {'Location': '3rd Floor',\n",
            "                                 'RoomID': 'EB403',\n",
            "                                 'Type': 'Classroom'},\n",
            "                                {'Location': '3rd Floor',\n",
            "                                 'RoomID': 'EB404',\n",
            "                                 'Type': 'Classroom'},\n",
            "                                {'Location': '3rd Floor',\n",
            "                                 'RoomID': 'EB405',\n",
            "                                 'Type': 'Classroom'},\n",
            "                                {'Location': '3rd Floor',\n",
            "                                 'RoomID': 'EB406',\n",
            "                                 'Type': 'Classroom'},\n",
            "                                {'Location': '3rd Floor',\n",
            "                                 'RoomID': 'EB407',\n",
            "                                 'Type': 'Classroom'},\n",
            "                                {'Location': '3rd Floor',\n",
            "                                 'RoomID': 'EB408',\n",
            "                                 'Type': 'Computer Lab'}],\n",
            "                      'search_terms': ['engineering block',\n",
            "                                       'engineering',\n",
            "                                       'eb',\n",
            "                                       'btech block',\n",
            "                                       'tech block']}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a flat 'entries' list from blocks and their rooms/places\n",
        "from rapidfuzz import process, fuzz\n",
        "entries = []            # each entry: {id,name,type,location,desc,raw,block}\n",
        "coord_map = {}          # id -> (x,y) if coordinates exist\n",
        "\n",
        "def add_entry(block_name, item):\n",
        "    eid = item.get('RoomID') or item.get('PlaceID') or item.get('Name') or item.get('id') or None\n",
        "    if not eid:\n",
        "        # make best-effort id\n",
        "        eid = item.get('Name') or item.get('RoomID') or f\"{block_name}_unknown_{len(entries)}\"\n",
        "    name = item.get('Name') or eid\n",
        "    typ = item.get('Type') or item.get('Category') or ''\n",
        "    loc = item.get('Location') or item.get('Floor') or ''\n",
        "    desc = item.get('Description') or item.get('Keywords') or item.get('Note') or ''\n",
        "    # search terms: include any helpful fields\n",
        "    search_terms = []\n",
        "    for k in ('search_keywords','search_terms','keywords'):\n",
        "        if k in item:\n",
        "            v = item[k]\n",
        "            if isinstance(v, list):\n",
        "                search_terms.extend(v)\n",
        "            elif isinstance(v, str):\n",
        "                search_terms.append(v)\n",
        "    raw = ' '.join([str(v) for v in [eid, name, typ, loc, desc] + search_terms if v])\n",
        "    entries.append({'id':eid, 'name':name, 'type':typ, 'location':loc, 'desc':desc, 'raw':raw, 'block':block_name})\n",
        "    # look for coordinates in common fields\n",
        "    for k in ('coordinates','coord','position','xy','location_coords'):\n",
        "        if k in item:\n",
        "            try:\n",
        "                c = item[k]\n",
        "                if isinstance(c, (list, tuple)) and len(c) >= 2:\n",
        "                    x, y = float(c[0]), float(c[1])\n",
        "                    coord_map[eid] = (x, y)\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "# iterate dataset\n",
        "for block_name, block_value in campus.items():\n",
        "    # if block contains a list of rooms under 'rooms', 'places', etc.\n",
        "    for key in ('rooms','places','locations','items','rooms_list'):\n",
        "        if isinstance(block_value, dict) and key in block_value and isinstance(block_value[key], list):\n",
        "            for item in block_value[key]:\n",
        "                add_entry(block_name, item)\n",
        "    # sometimes rooms are top-level list directly\n",
        "    if isinstance(block_value, list):\n",
        "        for item in block_value:\n",
        "            add_entry(block_name, item)\n",
        "    # also add block as an entry (helps queries like \"Engineering block\")\n",
        "    add_entry(block_name, {'Name': block_name, 'Type': 'Block', 'Description': block_value.get('description') if isinstance(block_value, dict) else ''})\n",
        "\n",
        "print(\"Built index with\", len(entries), \"entries.\")\n",
        "print(\"Coordinates available for\", len(coord_map), \"entries.\")\n",
        "# show a sample\n",
        "entries[:3]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K58sF5LlOCDO",
        "outputId": "de826e0d-10db-4da6-ee90-d6f6769433a3"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Built index with 132 entries.\n",
            "Coordinates available for 0 entries.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'id': 'EB101',\n",
              "  'name': 'EB101',\n",
              "  'type': 'Classroom',\n",
              "  'location': 'Ground Floor',\n",
              "  'desc': '',\n",
              "  'raw': 'EB101 EB101 Classroom Ground Floor',\n",
              "  'block': 'EngineeringBlock'},\n",
              " {'id': 'EB102',\n",
              "  'name': 'EB102',\n",
              "  'type': 'Computer Lab',\n",
              "  'location': 'Ground Floor',\n",
              "  'desc': '',\n",
              "  'raw': 'EB102 EB102 Computer Lab Ground Floor',\n",
              "  'block': 'EngineeringBlock'},\n",
              " {'id': 'EB103',\n",
              "  'name': 'EB103',\n",
              "  'type': 'Computer Lab',\n",
              "  'location': 'Ground Floor',\n",
              "  'desc': '',\n",
              "  'raw': 'EB103 EB103 Computer Lab Ground Floor',\n",
              "  'block': 'EngineeringBlock'}]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fuzzy search helper using RapidFuzz\n",
        "from rapidfuzz import process, fuzz\n",
        "\n",
        "def fuzzy_search(query, topk=5, score_cutoff=50):\n",
        "    choices = {i: e['raw'] for i,e in enumerate(entries)}\n",
        "    results_raw = process.extract(query, choices, scorer=fuzz.WRatio, limit=topk)\n",
        "    results = []\n",
        "    for match_str, score, idx in results_raw:\n",
        "        if score >= score_cutoff:\n",
        "            e = entries[idx]\n",
        "            results.append({'score': score, 'id': e['id'], 'name': e['name'], 'type': e['type'], 'location': e['location'], 'desc': e['desc'], 'block': e['block']})\n",
        "    return results\n",
        "\n",
        "# quick test\n",
        "print(\"Fuzzy test for 'library':\", fuzzy_search('library', topk=5))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tu4wWy_sOGxy",
        "outputId": "01d0f49b-4ae6-4a65-8a17-9858a186d75f"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fuzzy test for 'library': [{'score': 90.0, 'id': 'LOC003', 'name': 'Library', 'type': '', 'location': 'Ground', 'desc': 'Campus library', 'block': 'IGSM_Block'}, {'score': 77.14285714285715, 'id': 'SVH110', 'name': 'SVH110', 'type': 'CET Library', 'location': 'Ground Floor', 'desc': '', 'block': 'SVH_Block'}, {'score': 60.0, 'id': 'SVH', 'name': 'SVH', 'type': 'Main Academic Block', 'location': 'B.Tech classes, labs, library, seminar halls, exam cells', 'desc': '', 'block': 'SVH_Block'}, {'score': 60.0, 'id': 'SVH_Block', 'name': 'SVH_Block', 'type': 'Block', 'location': '', 'desc': 'SVH (Main Academic Block) includes B.Tech classrooms, computer labs, cloud lab, CET library, seminar halls, innovation center, and examination cells.', 'block': 'SVH_Block'}, {'score': 60.0, 'id': 'IGSM_Block', 'name': 'IGSM_Block', 'type': 'Block', 'location': '', 'desc': 'IGSM administrative and academic block containing offices (VC, Pro VC, COO, Registrar), meeting rooms, faculty cabins, classrooms, auditorium, library and medical room.', 'block': 'IGSM_Block'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Semantic search using sentence-transformers\n",
        "# This cell may download model weights on first run\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "\n",
        "print(\"Loading sentence-transformers model (all-MiniLM-L6-v2)...\")\n",
        "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')  # small & fast\n",
        "texts = [e['raw'] for e in entries]\n",
        "embeddings = sbert_model.encode(texts, show_progress_bar=True, convert_to_numpy=True)\n",
        "# normalize embeddings for cosine similarity\n",
        "norms = np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
        "embeddings = embeddings / (norms + 1e-9)\n",
        "print(\"Embeddings ready. Shape:\", embeddings.shape)\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "def semantic_search(query, topk=5):\n",
        "    q_emb = sbert_model.encode([query], convert_to_numpy=True)\n",
        "    q_emb = q_emb / (np.linalg.norm(q_emb) + 1e-9)\n",
        "    sims = cosine_similarity(q_emb, embeddings)[0]\n",
        "    idxs = list(np.argsort(-sims)[:topk])\n",
        "    results = []\n",
        "    for i in idxs:\n",
        "        results.append({'score': float(sims[i])*100, 'id': entries[i]['id'], 'name': entries[i]['name'], 'type': entries[i]['type'], 'location': entries[i]['location'], 'desc': entries[i]['desc'], 'block': entries[i]['block']})\n",
        "    return results\n",
        "\n",
        "# quick test\n",
        "print(\"Semantic test for 'library':\", semantic_search('library', topk=5))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121,
          "referenced_widgets": [
            "34c48982a0644056a50ec3e2a0970eeb",
            "0c9c014c5007477a8fc55055297047de",
            "0492325b58184385b533638944c8aeb4",
            "9a7f062781ef4c9eb082be2b55b0bd92",
            "a4247d6834924c80817193949cd07aa8",
            "56101ead3e44409cb07043251089c298",
            "b36c8703e96b4e3494b565f1583eb2ac",
            "0f9972cc1eb2409abca4355a61e6ae18",
            "58a6718f25d0444a84fb2504390421b8",
            "7b136711b5e64062993c4f7313b6f038",
            "048606f7cdd94f29a67894d2c0a50a4d"
          ]
        },
        "id": "vfitaIRvOKsL",
        "outputId": "5d2d643a-710a-406f-bc5e-30773ca03677"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading sentence-transformers model (all-MiniLM-L6-v2)...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "34c48982a0644056a50ec3e2a0970eeb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embeddings ready. Shape: (132, 384)\n",
            "Semantic test for 'library': [{'score': 55.630528926849365, 'id': 'LOC003', 'name': 'Library', 'type': '', 'location': 'Ground', 'desc': 'Campus library', 'block': 'IGSM_Block'}, {'score': 35.726022720336914, 'id': 'SVH', 'name': 'SVH', 'type': 'Main Academic Block', 'location': 'B.Tech classes, labs, library, seminar halls, exam cells', 'desc': '', 'block': 'SVH_Block'}, {'score': 31.81600570678711, 'id': 'SVH_Block', 'name': 'SVH_Block', 'type': 'Block', 'location': '', 'desc': 'SVH (Main Academic Block) includes B.Tech classrooms, computer labs, cloud lab, CET library, seminar halls, innovation center, and examination cells.', 'block': 'SVH_Block'}, {'score': 31.728774309158325, 'id': 'EB302', 'name': 'EB302', 'type': 'Faculty Room', 'location': '2nd Floor', 'desc': '', 'block': 'EngineeringBlock'}, {'score': 31.365221738815308, 'id': 'GF12', 'name': 'Basketball Court', 'type': 'Sports', 'location': 'Near CET Boys and CET Girls Hostel', 'desc': ['basketball', 'sports'], 'block': 'GeneralFacilities'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a simple undirected graph between coordinate nodes (k-nearest neighbors)\n",
        "import networkx as nx, math\n",
        "\n",
        "G = nx.Graph()\n",
        "for eid, (x,y) in coord_map.items():\n",
        "    G.add_node(eid, pos=(x,y))\n",
        "\n",
        "nodes = list(G.nodes())\n",
        "for i in range(len(nodes)):\n",
        "    xi, yi = G.nodes[nodes[i]]['pos']\n",
        "    # compute distances to others and connect to nearest N neighbors\n",
        "    dists = []\n",
        "    for j in range(len(nodes)):\n",
        "        if i == j: continue\n",
        "        xj, yj = G.nodes[nodes[j]]['pos']\n",
        "        d = math.hypot(xi-xj, yi-yj)\n",
        "        dists.append((d, nodes[j]))\n",
        "    dists.sort()\n",
        "    # connect to up to 6 nearest neighbors (tune as needed)\n",
        "    for d, nb in dists[:6]:\n",
        "        if not G.has_edge(nodes[i], nb):\n",
        "            G.add_edge(nodes[i], nb, weight=d)\n",
        "\n",
        "print(\"Graph built: nodes=\", G.number_of_nodes(), \"edges=\", G.number_of_edges())\n",
        "\n",
        "# A* routing helper\n",
        "def euclidean(a, b):\n",
        "    x1,y1 = G.nodes[a]['pos']\n",
        "    x2,y2 = G.nodes[b]['pos']\n",
        "    return math.hypot(x1-x2, y1-y2)\n",
        "\n",
        "def shortest_path_a_star(start_id, goal_id):\n",
        "    if start_id not in G or goal_id not in G:\n",
        "        return None\n",
        "    try:\n",
        "        path = nx.astar_path(G, start_id, goal_id, heuristic=euclidean, weight='weight')\n",
        "        length = nx.path_weight(G, path, weight='weight')\n",
        "        return {'path': path, 'length': length}\n",
        "    except Exception as e:\n",
        "        # disconnected or other failure\n",
        "        return None\n",
        "\n",
        "# Example (only works if both ids have coords)\n",
        "# print(shortest_path_a_star('RoomA', 'RoomB'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9N1ymsbOapE",
        "outputId": "75aa7f81-ba9b-4e89-c603-290f0a5fc4d3"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graph built: nodes= 0 edges= 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assistant response logic that picks search mode and optionally computes route\n",
        "import random\n",
        "\n",
        "def witty_reply():\n",
        "    return random.choice([\n",
        "        \"I'm NAVIILM — your campus compass with jokes.\",\n",
        "        \"Maps, coffee, and Wi-Fi — I know where they hide.\",\n",
        "        \"Lost? Don't worry. I will not tell your professor.\"\n",
        "    ])\n",
        "\n",
        "def assistant_response(user_text, search_mode='semantic', from_location=None, want_route=False):\n",
        "    q = user_text.strip()\n",
        "    # choose search\n",
        "    if search_mode == 'semantic':\n",
        "        results = semantic_search(q, topk=6)\n",
        "    else:\n",
        "        results = fuzzy_search(q, topk=6)\n",
        "\n",
        "    if not results:\n",
        "        return witty_reply() + \" — I couldn't find that. Try another name or check spelling.\"\n",
        "\n",
        "    top = results[0]\n",
        "    lines = []\n",
        "    lines.append(witty_reply())\n",
        "    lines.append(f\"Top match: **{top['name']}** ({top['type']}) — Block: {top['block']} — score {top['score']:.1f}%\")\n",
        "    lines.append(f\"Location/floor: {top['location']}\")\n",
        "    lines.append(f\"Description: {top['desc'] or 'No description available.'}\")\n",
        "\n",
        "    # show coordinates if available\n",
        "    if top['id'] in coord_map:\n",
        "        x,y = coord_map[top['id']]\n",
        "        lines.append(f\"Coordinates: ({x:.2f}, {y:.2f})\")\n",
        "\n",
        "        if want_route and from_location:\n",
        "            # find start id by searching from_location\n",
        "            start_candidates = (semantic_search(from_location, topk=1) if search_mode=='semantic' else fuzzy_search(from_location, topk=1))\n",
        "            if start_candidates and start_candidates[0]['id'] in coord_map:\n",
        "                start_id = start_candidates[0]['id']\n",
        "                route = shortest_path_a_star(start_id, top['id'])\n",
        "                if route:\n",
        "                    lines.append(f\"Route from **{start_candidates[0]['name']}** to **{top['name']}** — distance {route['length']:.2f}\")\n",
        "                    # optionally show node names\n",
        "                    lines.append(\"Steps: \" + \" -> \".join(route['path']))\n",
        "                else:\n",
        "                    lines.append(\"Could not compute route (graph may be disconnected).\")\n",
        "            else:\n",
        "                lines.append(\"Could not find coordinates for your starting location. Provide a starting place with coordinates.\")\n",
        "    else:\n",
        "        lines.append(\"No coordinates available for this place. Add `\\\"coordinates\\\": [x,y]` to enable routing.\")\n",
        "\n",
        "    # alternatives\n",
        "    if len(results) > 1:\n",
        "        lines.append(\"\\nOther matches:\")\n",
        "        for r in results[1:4]:\n",
        "            lines.append(f\"- {r['name']} ({r['type']}) — Block: {r['block']} — score {r['score']:.1f}%\")\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "# quick local test\n",
        "print(assistant_response(\"library\", search_mode='semantic'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBSnk5RLOmol",
        "outputId": "b1bc6f49-9bff-4ba8-9d53-46e24253a717"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maps, coffee, and Wi-Fi — I know where they hide.\n",
            "Top match: **Library** () — Block: IGSM_Block — score 55.6%\n",
            "Location/floor: Ground\n",
            "Description: Campus library\n",
            "No coordinates available for this place. Add `\"coordinates\": [x,y]` to enable routing.\n",
            "\n",
            "Other matches:\n",
            "- SVH (Main Academic Block) — Block: SVH_Block — score 35.7%\n",
            "- SVH_Block (Block) — Block: SVH_Block — score 31.8%\n",
            "- EB302 (Faculty Room) — Block: EngineeringBlock — score 31.7%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 9 (fixed) — gTTS helper: returns a filepath suitable for Gradio Audio(type='filepath')\n",
        "from gtts import gTTS\n",
        "import tempfile, os, uuid\n",
        "\n",
        "def tts_audio_filepath(text, lang='en'):\n",
        "    \"\"\"\n",
        "    Create a temporary mp3 file and return its path.\n",
        "    Caller (Gradio) will read it from this path.\n",
        "    We don't immediately delete the file because Gradio needs it to exist while serving.\n",
        "    You can periodically clean /tmp or later add cleanup logic if desired.\n",
        "    \"\"\"\n",
        "    # use a unique filename so concurrent requests don't collide\n",
        "    tmp_dir = tempfile.gettempdir()\n",
        "    fname = f\"naviilm_tts_{uuid.uuid4().hex}.mp3\"\n",
        "    fpath = os.path.join(tmp_dir, fname)\n",
        "    gTTS(text=text, lang=lang).save(fpath)\n",
        "    return fpath\n",
        "\n",
        "# quick manual test (uncomment to run):\n",
        "# path = tts_audio_filepath(\"Hello from NAVIILM. This is a voice test.\")\n",
        "# print(\"Audio written to:\", path)\n",
        "# from IPython.display import Audio, display\n",
        "# display(Audio(path, autoplay=False))\n"
      ],
      "metadata": {
        "id": "cgP-2wc1PDNd"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== Replacement cell: Better voice control (concise vs detailed) ======\n",
        "# Paste & run this cell in Colab AFTER you've run the earlier setup cells\n",
        "# (indexing, semantic/fuzzy functions, TTS helper, embeddings, etc.)\n",
        "\n",
        "import random\n",
        "from typing import Tuple\n",
        "\n",
        "# New assistant that returns both display text and a speakable short text\n",
        "def assistant_response_for_ui(user_text: str,\n",
        "                              search_mode: str = 'semantic',\n",
        "                              from_location: str | None = None,\n",
        "                              want_route: bool = False,\n",
        "                              voice_verbosity: str = 'concise'  # 'concise' or 'detailed'\n",
        "                             ) -> Tuple[str, str]:\n",
        "    \"\"\"\n",
        "    Returns (display_text, speak_text)\n",
        "    - display_text: full textual response (shown on screen)\n",
        "    - speak_text: short/concise text to send to TTS according to voice_verbosity\n",
        "    \"\"\"\n",
        "    q = user_text.strip()\n",
        "    # use existing search helpers\n",
        "    results = semantic_search(q, topk=6) if search_mode == 'semantic' else fuzzy_search(q, topk=6)\n",
        "    if not results:\n",
        "        display = \"Sorry — I couldn't find that place. Try another name or spelling.\"\n",
        "        speak = \"I couldn't find that place. Try another name.\"\n",
        "        return display, speak\n",
        "\n",
        "    top = results[0]\n",
        "    # Build display (full) text\n",
        "    lines = []\n",
        "    lines.append(random.choice([\n",
        "        \"I'm NAVIILM — your campus guide (text & voice).\",\n",
        "        \"Yeh raha tumhara campus helper!\",\n",
        "        \"NAVIILM bol raha hai — details neeche dekh lo.\"\n",
        "    ]))\n",
        "    lines.append(f\"**Top match:** {top['name']} ({top['type'] or 'N/A'}) — Block: {top['block']} — score {top['score']:.1f}%\")\n",
        "    lines.append(f\"Location / Floor: {top['location'] or 'N/A'}\")\n",
        "    lines.append(f\"Description: {top['desc'] or 'No description available.'}\")\n",
        "\n",
        "    # Coordinates + routing info (if requested)\n",
        "    if top['id'] in coord_map:\n",
        "        x, y = coord_map[top['id']]\n",
        "        lines.append(f\"Coordinates: ({x:.2f}, {y:.2f})\")\n",
        "        if want_route and from_location:\n",
        "            # find start\n",
        "            start_candidates = (semantic_search(from_location, topk=1) if search_mode=='semantic' else fuzzy_search(from_location, topk=1))\n",
        "            if start_candidates and start_candidates[0]['id'] in coord_map:\n",
        "                start_id = start_candidates[0]['id']\n",
        "                route = shortest_path_a_star(start_id, top['id'])\n",
        "                if route:\n",
        "                    lines.append(f\"Route from {start_candidates[0]['name']} → {top['name']}: distance {route['length']:.2f}\")\n",
        "                    lines.append(\"Steps: \" + \" -> \".join(route['path']))\n",
        "                else:\n",
        "                    lines.append(\"Could not compute route (graph disconnected).\")\n",
        "            else:\n",
        "                lines.append(\"Starting location doesn't have coordinates; cannot compute route.\")\n",
        "    else:\n",
        "        lines.append('No coordinates for this place. Add \"coordinates\": [x,y] in dataset to enable routing.')\n",
        "\n",
        "    # Add other matches in display (but not required for voice)\n",
        "    if len(results) > 1:\n",
        "        lines.append(\"\\n**Other matches:**\")\n",
        "        for r in results[1:4]:\n",
        "            lines.append(f\"- {r['name']} ({r['type'] or 'N/A'}) — Block: {r['block']} — score {r['score']:.1f}%\")\n",
        "\n",
        "    display_text = \"\\n\".join(lines)\n",
        "\n",
        "    # Build speak_text according to voice_verbosity\n",
        "    # concise: only top name, type, block, floor; NO percentages, NO other matches\n",
        "    # detailed: include percentages and a short list of other matches\n",
        "    if voice_verbosity == 'concise':\n",
        "        speak_parts = [f\"{top['name']} in {top['block']}.\"]\n",
        "        if top['location']:\n",
        "            speak_parts.append(f\"Located on {top['location']}.\")\n",
        "        if top['desc']:\n",
        "            # keep description short (max ~100 chars)\n",
        "            short_desc = (top['desc'] if isinstance(top['desc'], str) else \" \".join(top['desc']))[:100]\n",
        "            if short_desc:\n",
        "                speak_parts.append(short_desc)\n",
        "        speak_text = \" \".join(speak_parts)\n",
        "    else:\n",
        "        # detailed voice: include score and up to 2 alternatives\n",
        "        speak_parts = [f\"Top match {top['name']}. Type: {top['type'] or 'N A'}. Block: {top['block']}. Score {int(round(top['score']))} percent.\"]\n",
        "        if top['location']:\n",
        "            speak_parts.append(f\"Floor: {top['location']}.\")\n",
        "        if top['desc']:\n",
        "            short_desc = (top['desc'] if isinstance(top['desc'], str) else \" \".join(top['desc']))[:120]\n",
        "            if short_desc:\n",
        "                speak_parts.append(short_desc)\n",
        "        # alternatives\n",
        "        alt_cnt = min(2, max(0, len(results)-1))\n",
        "        if alt_cnt > 0:\n",
        "            alt_texts = []\n",
        "            for r in results[1:1+alt_cnt]:\n",
        "                alt_texts.append(f\"{r['name']} ({int(round(r['score']))} percent)\")\n",
        "            speak_parts.append(\"Other matches: \" + \", \".join(alt_texts) + \".\")\n",
        "        speak_text = \" \".join(speak_parts)\n",
        "\n",
        "    # final safety: keep speak_text short (<= 350 chars) to avoid overly long TTS\n",
        "    if len(speak_text) > 350:\n",
        "        speak_text = speak_text[:347] + \".\"\n",
        "\n",
        "    return display_text, speak_text\n",
        "\n",
        "\n",
        "# Replace the gradio callback to use the new assistant_response_for_ui and new voice verbosity control\n",
        "import gradio as gr\n",
        "\n",
        "def gradio_fn_improved(user_input, mode, voice_verbosity, speak_flag, from_loc, do_route):\n",
        "    display_text, speak_text = assistant_response_for_ui(\n",
        "        user_input,\n",
        "        search_mode=mode,\n",
        "        from_location=from_loc,\n",
        "        want_route=do_route,\n",
        "        voice_verbosity=voice_verbosity\n",
        "    )\n",
        "    audio_path = None\n",
        "    if speak_flag:\n",
        "        # use existing tts_audio_filepath helper to create mp3 for the speak_text\n",
        "        audio_path = tts_audio_filepath(speak_text)\n",
        "    return display_text, (audio_path if audio_path else None)\n",
        "\n",
        "# Build a fresh demo UI (or you can update your existing demo)\n",
        "with gr.Blocks() as improved_demo:\n",
        "    gr.Markdown(\"## NAVIILM — Improved Voice (Concise by default)\\n(Voice will speak only top result unless you choose 'detailed'.)\")\n",
        "    with gr.Row():\n",
        "        txt = gr.Textbox(lines=2, placeholder='Ask: Where is the library? Or \"Locate Box Cafe\"', label='Your question')\n",
        "    with gr.Row():\n",
        "        mode = gr.Radio(['semantic','fuzzy'], value='semantic', label='Search mode')\n",
        "        voice_verbosity = gr.Radio(['concise','detailed'], value='concise', label='Voice verbosity')\n",
        "        speak = gr.Checkbox(label='Play voice answer', value=False)\n",
        "    from_loc = gr.Textbox(lines=1, placeholder='Optional: starting location (for routing)', label='Start location (optional)')\n",
        "    do_route = gr.Checkbox(label='Compute route (requires coordinates)', value=False)\n",
        "    out_text = gr.Markdown()\n",
        "    out_audio = gr.Audio(type='filepath', label='Voice answer (mp3 file)')\n",
        "    submit = gr.Button('Ask NAVIILM (improved)')\n",
        "    submit.click(fn=gradio_fn_improved, inputs=[txt, mode, voice_verbosity, speak, from_loc, do_route], outputs=[out_text, out_audio])\n",
        "\n",
        "# Launch note: if you already have an app running, stop it and run improved_demo.launch(share=True)\n",
        "print(\"Cell ready. Now run: improved_demo.launch(share=True) to open the improved UI.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RO_UtbFWvMG",
        "outputId": "bdf2e79a-7feb-4af8-f6e9-a79161014979"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cell ready. Now run: improved_demo.launch(share=True) to open the improved UI.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DkBCHrS6W25f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NAVIILM Quick Diagnostic Cell\n",
        "import os, sys, traceback, json, tempfile\n",
        "print(\"=== NAVIILM Diagnostic ===\")\n",
        "DATA_PATH = \"/content/bigdata.json\"\n",
        "print(\"Dataset path:\", DATA_PATH)\n",
        "print(\"Exists:\", os.path.exists(DATA_PATH))\n",
        "if os.path.exists(DATA_PATH):\n",
        "    print(\"Size (bytes):\", os.path.getsize(DATA_PATH))\n",
        "    try:\n",
        "        with open(DATA_PATH, \"r\", encoding=\"utf-8\") as f:\n",
        "            small = f.read(1000)\n",
        "        print(\"Preview (first 1000 chars):\")\n",
        "        print(small[:1000])\n",
        "    except Exception as e:\n",
        "        print(\"Could not preview file:\", e)\n",
        "\n",
        "# Helper to test a symbol exists\n",
        "def has(name):\n",
        "    return name in globals() or name in locals()\n",
        "\n",
        "symbols = [\n",
        "    'entries', 'coord_map', 'fuzzy_search', 'semantic_search',\n",
        "    'assistant_response', 'tts_audio_filepath', 'tts_audio_bytes',\n",
        "    'G', 'shortest_path_a_star', 'sbert_model'\n",
        "]\n",
        "print(\"\\nSymbols presence:\")\n",
        "for s in symbols:\n",
        "    print(f\" - {s}: {'YES' if has(s) else 'NO'}\")\n",
        "\n",
        "# Test entries\n",
        "try:\n",
        "    if has('entries'):\n",
        "        print(\"\\nNumber of indexed entries:\", len(entries))\n",
        "        print(\"Sample entry[0]:\")\n",
        "        import pprint\n",
        "        pprint.pprint(entries[0])\n",
        "    else:\n",
        "        print(\"\\nIndex 'entries' not found. Run the index-building cell (Cell 4).\")\n",
        "except Exception as e:\n",
        "    print(\"Error inspecting entries:\", e)\n",
        "    traceback.print_exc(limit=1)\n",
        "\n",
        "# Test fuzzy search (if available)\n",
        "try:\n",
        "    if has('fuzzy_search'):\n",
        "        print(\"\\nRunning fuzzy_search('library') ...\")\n",
        "        print(fuzzy_search('library', topk=5))\n",
        "    else:\n",
        "        print(\"\\nFuzzy search function missing. Run the fuzzy search cell (Cell 5).\")\n",
        "except Exception as e:\n",
        "    print(\"fuzzy_search raised an error:\", e)\n",
        "    traceback.print_exc(limit=1)\n",
        "\n",
        "# Test semantic search (if available)\n",
        "try:\n",
        "    if has('semantic_search'):\n",
        "        print(\"\\nRunning semantic_search('library') ... (this requires sbert_model & embeddings)\")\n",
        "        print(semantic_search('library', topk=5))\n",
        "    else:\n",
        "        print(\"\\nSemantic search missing. Run the sentence-transformers cell (Cell 6).\")\n",
        "except Exception as e:\n",
        "    print(\"semantic_search raised an error:\", e)\n",
        "    traceback.print_exc(limit=1)\n",
        "\n",
        "# Test assistant_response\n",
        "try:\n",
        "    if has('assistant_response'):\n",
        "        print(\"\\nAssistant test: assistant_response('Where is the library?', search_mode='semantic')\\n\")\n",
        "        out = assistant_response(\"Where is the library?\", search_mode='semantic')\n",
        "        print(out)\n",
        "    else:\n",
        "        print(\"\\nassistant_response not defined. Run the assistant logic cell (Cell 8).\")\n",
        "except Exception as e:\n",
        "    print(\"assistant_response raised an error:\", e)\n",
        "    traceback.print_exc(limit=1)\n",
        "\n",
        "# Test TTS helper (writes a small temp file) for the fixed filepath version\n",
        "try:\n",
        "    if has('tts_audio_filepath'):\n",
        "        print(\"\\nTesting tts_audio_filepath(...) — writing temp MP3\")\n",
        "        p = tts_audio_filepath(\"NAV IILM test audio.\")\n",
        "        print(\"Wrote TTS file to:\", p, \"Exists:\", os.path.exists(p), \"Size:\", os.path.getsize(p) if os.path.exists(p) else 'n/a')\n",
        "    elif has('tts_audio_bytes'):\n",
        "        print(\"\\nFound tts_audio_bytes — generating bytes\")\n",
        "        b = tts_audio_bytes(\"NAV IILM test audio.\")\n",
        "        print(\"Generated bytes length:\", len(b))\n",
        "    else:\n",
        "        print(\"\\nNo TTS helpers found. Run the fixed TTS cell (Cell 9).\")\n",
        "except Exception as e:\n",
        "    print(\"TTS helper raised an error:\", e)\n",
        "    traceback.print_exc(limit=1)\n",
        "\n",
        "# Test routing (if graph exists and has >=2 nodes)\n",
        "try:\n",
        "    if has('G') and hasattr(G, 'number_of_nodes'):\n",
        "        print(\"\\nRouting graph nodes:\", G.number_of_nodes(), \"edges:\", G.number_of_edges())\n",
        "        if G.number_of_nodes() >= 2 and has('shortest_path_a_star'):\n",
        "            nodes = list(G.nodes())[:2]\n",
        "            print(\"Attempting route between\", nodes[0], \"and\", nodes[1])\n",
        "            r = shortest_path_a_star(nodes[0], nodes[1])\n",
        "            print(\"Route result:\", r)\n",
        "        else:\n",
        "            print(\"Routing graph exists but not enough nodes or shortest_path_a_star missing.\")\n",
        "    else:\n",
        "        print(\"\\nRouting graph 'G' not found. Run the routing graph cell (Cell 7) after adding coordinates.\")\n",
        "except Exception as e:\n",
        "    print(\"Routing check error:\", e)\n",
        "    traceback.print_exc(limit=1)\n",
        "\n",
        "# Check Gradio presence and version\n",
        "try:\n",
        "    import gradio as gr\n",
        "    print(\"\\nGradio version:\", gr.__version__)\n",
        "except Exception as e:\n",
        "    print(\"\\nGradio not available or import failed:\", e)\n",
        "\n",
        "print(\"\\n=== Diagnostic complete ===\")\n",
        "print(\"If something printed 'NO' or you saw tracebacks, re-run the corresponding cells above the Gradio UI one-by-one, then run this diagnostic again.\")\n",
        "print(\"File used in this diagnostic: file:/content/bigdata.json\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdgnoxScQhQ_",
        "outputId": "7081720a-fced-401e-b65d-9fd8af9da03e"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== NAVIILM Diagnostic ===\n",
            "Dataset path: /content/bigdata.json\n",
            "Exists: True\n",
            "Size (bytes): 19254\n",
            "Preview (first 1000 chars):\n",
            "{\n",
            "  \"CampusData\": {\n",
            "    \"EngineeringBlock\": {\n",
            "      \"search_terms\": [\"engineering block\", \"engineering\", \"eb\", \"btech block\", \"tech block\"],\n",
            "      \"description\": \"The Engineering Block consists of fully furnished classrooms, computer labs, faculty rooms, water coolers, and vending machines. It is designed for B.Tech students with easy access to academic facilities.\",\n",
            "      \"rooms\": [\n",
            "        {\"RoomID\": \"EB101\", \"Type\": \"Classroom\", \"Location\": \"Ground Floor\"},\n",
            "        {\"RoomID\": \"EB102\", \"Type\": \"Computer Lab\", \"Location\": \"Ground Floor\"},\n",
            "        {\"RoomID\": \"EB103\", \"Type\": \"Computer Lab\", \"Location\": \"Ground Floor\"},\n",
            "        {\"RoomID\": \"EB104\", \"Type\": \"Computer Lab\", \"Location\": \"Ground Floor\"},\n",
            "        {\"RoomID\": \"EB105\", \"Type\": \"Computer Lab\", \"Location\": \"Ground Floor\"},\n",
            "        {\"RoomID\": \"EB106\", \"Type\": \"Classroom\", \"Location\": \"Ground Floor\"},\n",
            "\n",
            "        {\"RoomID\": \"EB201\", \"Type\": \"Classroom\", \"Location\": \"1st Floor\"},\n",
            "        {\"RoomID\": \"EB202\", \"Type\": \"Classroom\", \"Locatio\n",
            "\n",
            "Symbols presence:\n",
            " - entries: YES\n",
            " - coord_map: YES\n",
            " - fuzzy_search: YES\n",
            " - semantic_search: YES\n",
            " - assistant_response: YES\n",
            " - tts_audio_filepath: YES\n",
            " - tts_audio_bytes: YES\n",
            " - G: YES\n",
            " - shortest_path_a_star: YES\n",
            " - sbert_model: YES\n",
            "\n",
            "Number of indexed entries: 132\n",
            "Sample entry[0]:\n",
            "{'block': 'EngineeringBlock',\n",
            " 'desc': '',\n",
            " 'id': 'EB101',\n",
            " 'location': 'Ground Floor',\n",
            " 'name': 'EB101',\n",
            " 'raw': 'EB101 EB101 Classroom Ground Floor',\n",
            " 'type': 'Classroom'}\n",
            "\n",
            "Running fuzzy_search('library') ...\n",
            "[{'score': 90.0, 'id': 'LOC003', 'name': 'Library', 'type': '', 'location': 'Ground', 'desc': 'Campus library', 'block': 'IGSM_Block'}, {'score': 77.14285714285715, 'id': 'SVH110', 'name': 'SVH110', 'type': 'CET Library', 'location': 'Ground Floor', 'desc': '', 'block': 'SVH_Block'}, {'score': 60.0, 'id': 'SVH', 'name': 'SVH', 'type': 'Main Academic Block', 'location': 'B.Tech classes, labs, library, seminar halls, exam cells', 'desc': '', 'block': 'SVH_Block'}, {'score': 60.0, 'id': 'SVH_Block', 'name': 'SVH_Block', 'type': 'Block', 'location': '', 'desc': 'SVH (Main Academic Block) includes B.Tech classrooms, computer labs, cloud lab, CET library, seminar halls, innovation center, and examination cells.', 'block': 'SVH_Block'}, {'score': 60.0, 'id': 'IGSM_Block', 'name': 'IGSM_Block', 'type': 'Block', 'location': '', 'desc': 'IGSM administrative and academic block containing offices (VC, Pro VC, COO, Registrar), meeting rooms, faculty cabins, classrooms, auditorium, library and medical room.', 'block': 'IGSM_Block'}]\n",
            "\n",
            "Running semantic_search('library') ... (this requires sbert_model & embeddings)\n",
            "[{'score': 55.630528926849365, 'id': 'LOC003', 'name': 'Library', 'type': '', 'location': 'Ground', 'desc': 'Campus library', 'block': 'IGSM_Block'}, {'score': 35.726022720336914, 'id': 'SVH', 'name': 'SVH', 'type': 'Main Academic Block', 'location': 'B.Tech classes, labs, library, seminar halls, exam cells', 'desc': '', 'block': 'SVH_Block'}, {'score': 31.81600570678711, 'id': 'SVH_Block', 'name': 'SVH_Block', 'type': 'Block', 'location': '', 'desc': 'SVH (Main Academic Block) includes B.Tech classrooms, computer labs, cloud lab, CET library, seminar halls, innovation center, and examination cells.', 'block': 'SVH_Block'}, {'score': 31.728774309158325, 'id': 'EB302', 'name': 'EB302', 'type': 'Faculty Room', 'location': '2nd Floor', 'desc': '', 'block': 'EngineeringBlock'}, {'score': 31.365221738815308, 'id': 'GF12', 'name': 'Basketball Court', 'type': 'Sports', 'location': 'Near CET Boys and CET Girls Hostel', 'desc': ['basketball', 'sports'], 'block': 'GeneralFacilities'}]\n",
            "\n",
            "Assistant test: assistant_response('Where is the library?', search_mode='semantic')\n",
            "\n",
            "Maps, coffee, and Wi-Fi — I know where they hide.\n",
            "Top match: **Library** () — Block: IGSM_Block — score 59.3%\n",
            "Location/floor: Ground\n",
            "Description: Campus library\n",
            "No coordinates available for this place. Add `\"coordinates\": [x,y]` to enable routing.\n",
            "\n",
            "Other matches:\n",
            "- EB302 (Faculty Room) — Block: EngineeringBlock — score 36.7%\n",
            "- EB303 (Faculty Room) — Block: EngineeringBlock — score 36.2%\n",
            "- Basketball Court (Sports) — Block: GeneralFacilities — score 35.3%\n",
            "\n",
            "Testing tts_audio_filepath(...) — writing temp MP3\n",
            "Wrote TTS file to: /tmp/naviilm_tts_a7fcb936d6434aaebb701e14966bde63.mp3 Exists: True Size: 22464\n",
            "\n",
            "Routing graph nodes: 0 edges: 0\n",
            "Routing graph exists but not enough nodes or shortest_path_a_star missing.\n",
            "\n",
            "Gradio version: 5.49.1\n",
            "\n",
            "=== Diagnostic complete ===\n",
            "If something printed 'NO' or you saw tracebacks, re-run the corresponding cells above the Gradio UI one-by-one, then run this diagnostic again.\n",
            "File used in this diagnostic: file:/content/bigdata.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "demo.launch(share=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "id": "pYeCn2cbRosF",
        "outputId": "52d74a83-410e-491e-f75f-d2471ed3c5da"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://7dc5b1a8ff04631947.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://7dc5b1a8ff04631947.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "improved_demo.launch(share=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "id": "G1QwkHyUW4iD",
        "outputId": "dc91d76e-f1c6-4ec2-ef48-f9678e1acf1e"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://a2f8f8d6a2bef557ce.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://a2f8f8d6a2bef557ce.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    }
  ]
}